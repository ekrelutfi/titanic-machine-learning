{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read train and test data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Family Survival**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this feature was inspired by S.Xu's (https://www.kaggle.com/shunjiangxu/blood-is-thicker-than-water-friendship-forever)\n",
    "# and I take this code from konstantinmasich's (https://www.kaggle.com/konstantinmasich/titanic-0-82-0-83) beacause using simple code\n",
    "#this feature is about family survival chance.\n",
    "\n",
    "data = pd.concat((train, test))\n",
    "\n",
    "# Extract last name\n",
    "data['Last_Name'] = data['Name'].apply(lambda x: str.split(x, \",\")[0])\n",
    "\n",
    "# Fill in missing Fare value by overall Fare mean\n",
    "data['Fare'].fillna(data['Fare'].mean(), inplace=True)\n",
    "\n",
    "# Setting coin flip (e.g. random chance of surviving)\n",
    "default_survival_chance = 0.5\n",
    "data['Family_Survival'] = default_survival_chance\n",
    "\n",
    "# Grouping data by last name and fare - looking for families\n",
    "for grp, grp_df in data[['Survived','Name', 'Last_Name', 'Fare', 'Ticket', 'PassengerId',\n",
    "                           'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['Last_Name', 'Fare']):\n",
    "    \n",
    "    # If not equal to 1, a family is found \n",
    "    # Then work out survival chance depending on whether or not that family member survived\n",
    "    if (len(grp_df) != 1):\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            smax = grp_df.drop(ind)['Survived'].max()\n",
    "            smin = grp_df.drop(ind)['Survived'].min()\n",
    "            passID = row['PassengerId']\n",
    "            if (smax == 1.0):\n",
    "                data.loc[data['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "            elif (smin == 0.0):\n",
    "                data.loc[data['PassengerId'] == passID, 'Family_Survival'] = 0\n",
    "\n",
    "# Print the headline\n",
    "print(\"Number of passengers with family survival information:\", \n",
    "      data.loc[data['Family_Survival']!=0.5].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Title**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract Title every Passenger\n",
    "data['Title']=data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "#grouping Title Passenger by 'Rare','Miss','Mr','Mrs'\n",
    "data['Title'] = data['Title'].replace(['Don', 'Rev', 'Dr', 'Major', 'Lady', 'Sir',\n",
    "                                                'Col', 'Capt', 'Countess', 'Jonkheer', 'Dona'], 'Rare')\n",
    "data['Title'] = data['Title'].replace(['Ms',  'Mlle'], 'Miss')\n",
    "data['Title'] = data['Title'].replace(['Mme'], 'Mrs')\n",
    "\n",
    "#change this categorical feature to numeric\n",
    "c={'Mr': 0, 'Miss': 1, 'Mrs': 2, 'Master': 3, 'Rare': 4}\n",
    "data['Title'] = data.Title.map(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sex_conv = {'male': 1, 'female' : 0}\n",
    "data['Sex_cat'] = data['Sex'].map(Sex_conv).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deck/Cabin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create deck feature by first letter on Cabin and fill missing cabin by 'M'\n",
    "data['Deck'] = data.Cabin.apply(lambda x:x[0] if pd.notnull(x) else 'M')\n",
    "\n",
    "#change deck feature to numeric value\n",
    "d={'M': 0, 'C': 1, 'B': 2, 'D': 3, 'E': 4, 'A': 5, 'F': 6, 'G': 7, 'T': 8}\n",
    "data['Deck'] = data.Deck.map(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill missing value in age by median of age\n",
    "data.Age.fillna(data.Age.median(), inplace=True)\n",
    "\n",
    "#binning age feature\n",
    "data.loc[data['Age']<=22, 'Age'] = 0\n",
    "data.loc[(data['Age']>22) & (data['Age']<=28), 'Age'] = 1\n",
    "data.loc[(data['Age']>28) & (data['Age']<=35), 'Age'] = 2\n",
    "data.loc[(data['Age']>35) & (data['Age']<=80), 'Age'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embarked**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    914\n",
       "C    270\n",
       "Q    123\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill missing value in Embarked by most frequent value ('S')\n",
    "data.Embarked.fillna('S', inplace=True)\n",
    "\n",
    "#change feature to numerical feature\n",
    "e={'C':0, 'S':1, 'Q':2}\n",
    "data['Embarked'] = data.Embarked.map(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fare**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binning Fare feature by 5 bins\n",
    "data.loc[data['Fare'] <= 7.854, 'Fare'] = 0\n",
    "data.loc[(data['Fare'] > 7.854) & (data['Fare'] <= 10.5), 'Fare'] = 1\n",
    "data.loc[(data['Fare'] > 10.5) & (data['Fare'] <= 21.679), 'Fare'] = 2\n",
    "data.loc[(data['Fare'] > 21.679) & (data['Fare'] <= 39.688), 'Fare'] = 3\n",
    "data.loc[(data['Fare'] > 39.688) & (data['Fare'] <= 512.329), 'Fare'] = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**is_alone from SibSp and Parch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature that passanger is alone or not\n",
    "data['is_alone'] = data['SibSp'] + data['Parch']\n",
    "data['is_alone'] = data.is_alone.apply(lambda x: x/x if x!=0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create train and test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get train and test set\n",
    "n_train = train.shape[0]\n",
    "X_train = data[:n_train]\n",
    "X_test = data[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choosing feature that apply to the model and slice target ('Survived')\n",
    "y_train = X_train['Survived']\n",
    "X_train = X_train[['Age','Embarked','Fare','Parch','Pclass','SibSp','Family_Survival','Sex_cat','Title','Deck']]\n",
    "X_test = X_test[['Age','Embarked','Fare','Parch','Pclass','SibSp','Family_Survival','Sex_cat','Title','Deck']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Develop Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import model\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "log_reg = LogisticRegression()\n",
    "SGD = SGDClassifier()\n",
    "percep = Perceptron()\n",
    "tree = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "SVC = SVC()\n",
    "lin_SVC = LinearSVC()\n",
    "gauss = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier : 0.929292929\n",
      "Random Forest Classifier : 0.929292929\n",
      "KNN : 0.854096521\n",
      "Logistic Regression : 0.841750842\n",
      "Perceptron : 0.659932660\n",
      "Stochastic Gradient : 0.778900112\n",
      "SVC : 0.776655443\n",
      "Linear SVC : 0.841750842\n",
      "GaussianNB : 0.744107744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#run the model\n",
    "classifiers = [('Decision Tree Classifier', tree),\n",
    "               ('Random Forest Classifier', rf),\n",
    "              ('KNN', knn),\n",
    "              ('Logistic Regression', log_reg),\n",
    "              ('Perceptron', percep),\n",
    "              ('Stochastic Gradient', SGD),\n",
    "              ('SVC', SVC),\n",
    "              ('Linear SVC', lin_SVC),\n",
    "              ('GaussianNB', gauss)]\n",
    "# iterate over the defined list of tuples containing the classifiers\n",
    "for clf_name, clf in classifiers:\n",
    "    # fit clf to the data\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # predict the labels of the test\n",
    "    y_pred = clf.predict(X_train)\n",
    "    \n",
    "    # evaluate the accuracy of clf on the train set\n",
    "    print('{:s} : {:.9f}'.format(clf_name, accuracy_score(y_train, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>as you can see, top 3 model are Decision Tree, Random Forest and KNN.<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(oob_score=True, random_state=1),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [3, 4, 5, 6, 7],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'min_samples_leaf': [2, 4, 10, 12, 16],\n",
       "                         'n_estimators': [50, 100, 400, 700, 1000]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest Hyperparameter Tuning\n",
    "rf=RandomForestClassifier(oob_score=True, random_state=1)\n",
    "\n",
    "params_rf = {'criterion': [\"gini\",\"entropy\"], \n",
    "             'min_samples_leaf': [3,4,5,6,7], \n",
    "             'n_estimators': [50,100,400,700,1000], \n",
    "             'min_samples_leaf':[2,4,10,12,16],\n",
    "             'max_depth':[3,4,5,6,7],\n",
    "             'max_features':['auto','sqrt','log2']}\n",
    "\n",
    "grid_rf = GridSearchCV(estimator = rf,\n",
    "                        param_grid = params_rf,\n",
    "                        scoring= 'accuracy',\n",
    "                        n_jobs=-1\n",
    "                      )\n",
    "grid_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 4,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 10,\n",
       " 'n_estimators': 400}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get best parameter of Random Forest\n",
    "grid_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8529533613709119"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get best score\n",
    "grid_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make submission file of Random Forest with hyperparameter tuning\n",
    "submission = pd.DataFrame({'PassengerId':test['PassengerId'], \n",
    "                           'Survived': grid_rf.best_estimator_.predict(X_test).astype(int)})\n",
    "submission.to_csv('grid_rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> We got 0.81339 of submission score on Kaggle for Random Forest using Hyperparameter tuning <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Validation\n",
    "#print(cross_val_score(grid_rf.best_estimator_, X_train, y_train, cv=10, scoring='accuracy'))\n",
    "#print(cross_val_score(grid_rf.best_estimator_, X_train, y_train, cv=10, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['entropy', 'gini'],\n",
       "                         'max_depth': range(1, 30),\n",
       "                         'min_samples_leaf': range(1, 11),\n",
       "                         'min_samples_split': range(1, 7)},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision Tree hyperparameter tuning\n",
    "params_tree = {'max_depth': range(1,30),\n",
    "               'min_samples_leaf':range(1,11),\n",
    "               'min_samples_split': range(1,7),\n",
    "              'criterion': ['entropy', 'gini']\n",
    "              }\n",
    "grid_tree = GridSearchCV(estimator = tree,\n",
    "                        param_grid = params_tree,\n",
    "                        scoring= 'accuracy',\n",
    "                        n_jobs=-1,\n",
    "                        )\n",
    "grid_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "0.8506998932898122\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=3)\n"
     ]
    }
   ],
   "source": [
    "# get best parameter and score\n",
    "print(grid_tree.best_params_)\n",
    "print(grid_tree.best_score_)\n",
    "print(grid_tree.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make submission file\n",
    "submission = pd.DataFrame({'PassengerId':test['PassengerId'], \n",
    "                           'Survived': grid_tree.best_estimator_.predict(X_test).astype(int)})\n",
    "submission.to_csv('grid_tree.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've got 0.79665 score on Kaggle for Decision Tree using Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Validation\n",
    "#print(cross_val_score(grid_tree.best_estimator_, X_train, y_train, cv=10, scoring='accuracy'))\n",
    "#print(cross_val_score(grid_tree.best_estimator_, X_train, y_train, cv=10, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNneighbors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
       "                         'leaf_size': range(1, 31), 'n_neighbors': range(1, 31),\n",
       "                         'p': [1, 2, 5], 'weights': ['uniform', 'distance']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN hyperparameter tuning\n",
    "param_grid_knn = {'leaf_size':range(1,31), 'n_neighbors': range(1,31),\n",
    "                  'p':[1,2,5], 'weights':['uniform', 'distance'],\n",
    "                 'algorithm': ['auto','ball_tree','kd_tree', 'brute']}\n",
    "grid_knn = GridSearchCV(estimator=knn, param_grid=param_grid_knn, scoring='accuracy',\n",
    "                       n_jobs=-1)\n",
    "grid_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'ball_tree', 'leaf_size': 6, 'n_neighbors': 19, 'p': 1, 'weights': 'uniform'}\n",
      "0.8372167472223966\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=6, n_neighbors=19, p=1)\n"
     ]
    }
   ],
   "source": [
    "#get best parameter and score\n",
    "print(grid_knn.best_params_)\n",
    "print(grid_knn.best_score_)\n",
    "print(grid_knn.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make submission file\n",
    "submission = pd.DataFrame({'PassengerId':test['PassengerId'], \n",
    "                           'Survived': grid_knn.best_estimator_.predict(X_test).astype(int)})\n",
    "submission.to_csv('grid_knn.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've got 0.76076 on Kaggle for KNN using hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Validation\n",
    "#print(cross_val_score(grid_knn.best_estimator_, X_train, y_train, cv=10, scoring='accuracy'))\n",
    "#print(cross_val_score(grid_knn.best_estimator_, X_train, y_train, cv=10, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Voting Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:0.8552188552188552\n"
     ]
    }
   ],
   "source": [
    "classifiers = [('random forest', grid_rf.best_estimator_),\n",
    "              ('Decision Tree', grid_tree.best_estimator_),\n",
    "              ('KNN', grid_knn.best_estimator_)]\n",
    "vc=VotingClassifier(estimators=classifiers, voting='hard')\n",
    "vc.fit(X_train, y_train)\n",
    "y_pred_vc = vc.predict(X_train)\n",
    "print('accuracy score:{}'.format(accuracy_score(y_train, y_pred_vc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PassengerId':test['PassengerId'], \n",
    "                           'Survived': vc.predict(X_test).astype(int)})\n",
    "submission.to_csv('voting.csv', index=False)\n",
    "#submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've got 0.81100 on Kaggle for Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
